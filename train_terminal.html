<pre>(venv) <font color="#26A269"><b>geko@exodia</b></font>:<font color="#12488B"><b>~/unibo/unibo-nlp</b></font>$ time python3 train_lstm.py 
2025-01-25 15:55:37.999147: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2025-01-25 15:55:38.002630: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2025-01-25 15:55:38.013010: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1737816938.030953   28636 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1737816938.035931   28636 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-01-25 15:55:38.054255: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
loading dataset: 50it [00:00, 161.27it/s]
train data shape: (40000, 2)
test data shape:  (10000, 2)
tokenizing the test dataset
training with: {&apos;NUM_EPOCHS&apos;: 3, &apos;BATCH_SIZE&apos;: 64, &apos;REVIEW_MAX_LENGTH&apos;: 500}
nn: LSTM - Long Short-Term Memory
2025-01-25 15:55:45.120410: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
<b>Model: &quot;sequential&quot;</b>
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃<b> Layer (type)                         </b>┃<b> Output Shape                </b>┃<b>         Param # </b>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ embedding (<font color="#0087FF">Embedding</font>)                │ ?                           │     <font color="#00AF00">0</font> (unbuilt) │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ lstm (<font color="#0087FF">LSTM</font>)                          │ ?                           │     <font color="#00AF00">0</font> (unbuilt) │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense (<font color="#0087FF">Dense</font>)                        │ ?                           │     <font color="#00AF00">0</font> (unbuilt) │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
<b> Total params: </b><font color="#00AF00">0</font> (0.00 B)
<b> Trainable params: </b><font color="#00AF00">0</font> (0.00 B)
<b> Non-trainable params: </b><font color="#00AF00">0</font> (0.00 B)
None
training the model
Epoch 1/3
<b>500/500</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>79s</b> 155ms/step - accuracy: 0.7150 - loss: 0.8138 - val_accuracy: 0.8646 - val_loss: 0.3564
Epoch 2/3
<b>500/500</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>73s</b> 146ms/step - accuracy: 0.8714 - loss: 0.3487 - val_accuracy: 0.8572 - val_loss: 0.3558
Epoch 3/3
<b>500/500</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>73s</b> 146ms/step - accuracy: 0.8924 - loss: 0.2978 - val_accuracy: 0.8751 - val_loss: 0.3258
<b>313/313</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>10s</b> 30ms/step - accuracy: 0.8674 - loss: 0.3301  
LSTM with hyperparameters {&apos;NUM_EPOCHS&apos;: 3, &apos;BATCH_SIZE&apos;: 64, &apos;REVIEW_MAX_LENGTH&apos;: 500}
test loss:     0.3343100845813751
test accuracy: 0.8657000064849854
training with: {&apos;NUM_EPOCHS&apos;: 3, &apos;BATCH_SIZE&apos;: 64, &apos;REVIEW_MAX_LENGTH&apos;: 1000}
nn: LSTM - Long Short-Term Memory
<b>Model: &quot;sequential_1&quot;</b>
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃<b> Layer (type)                         </b>┃<b> Output Shape                </b>┃<b>         Param # </b>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ embedding_1 (<font color="#0087FF">Embedding</font>)              │ ?                           │     <font color="#00AF00">0</font> (unbuilt) │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ lstm_1 (<font color="#0087FF">LSTM</font>)                        │ ?                           │     <font color="#00AF00">0</font> (unbuilt) │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_1 (<font color="#0087FF">Dense</font>)                      │ ?                           │     <font color="#00AF00">0</font> (unbuilt) │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
<b> Total params: </b><font color="#00AF00">0</font> (0.00 B)
<b> Trainable params: </b><font color="#00AF00">0</font> (0.00 B)
<b> Non-trainable params: </b><font color="#00AF00">0</font> (0.00 B)
None
training the model
Epoch 1/3
<b>500/500</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>170s</b> 337ms/step - accuracy: 0.7218 - loss: 0.8300 - val_accuracy: 0.8684 - val_loss: 0.3406
Epoch 2/3
<b>500/500</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>167s</b> 333ms/step - accuracy: 0.8596 - loss: 0.3818 - val_accuracy: 0.8806 - val_loss: 0.3138
Epoch 3/3
<b>500/500</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>166s</b> 333ms/step - accuracy: 0.8951 - loss: 0.2996 - val_accuracy: 0.8773 - val_loss: 0.3178
<b>313/313</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>18s</b> 57ms/step - accuracy: 0.8761 - loss: 0.3168  
LSTM with hyperparameters {&apos;NUM_EPOCHS&apos;: 3, &apos;BATCH_SIZE&apos;: 64, &apos;REVIEW_MAX_LENGTH&apos;: 1000}
test loss:     0.32543736696243286
test accuracy: 0.8725000023841858
training with: {&apos;NUM_EPOCHS&apos;: 3, &apos;BATCH_SIZE&apos;: 128, &apos;REVIEW_MAX_LENGTH&apos;: 500}
nn: LSTM - Long Short-Term Memory
<b>Model: &quot;sequential_2&quot;</b>
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃<b> Layer (type)                         </b>┃<b> Output Shape                </b>┃<b>         Param # </b>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ embedding_2 (<font color="#0087FF">Embedding</font>)              │ ?                           │     <font color="#00AF00">0</font> (unbuilt) │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ lstm_2 (<font color="#0087FF">LSTM</font>)                        │ ?                           │     <font color="#00AF00">0</font> (unbuilt) │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_2 (<font color="#0087FF">Dense</font>)                      │ ?                           │     <font color="#00AF00">0</font> (unbuilt) │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
<b> Total params: </b><font color="#00AF00">0</font> (0.00 B)
<b> Trainable params: </b><font color="#00AF00">0</font> (0.00 B)
<b> Non-trainable params: </b><font color="#00AF00">0</font> (0.00 B)
None
training the model
Epoch 1/3
<b>250/250</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>54s</b> 210ms/step - accuracy: 0.6993 - loss: 1.0030 - val_accuracy: 0.8670 - val_loss: 0.3590
Epoch 2/3
<b>250/250</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>52s</b> 208ms/step - accuracy: 0.8677 - loss: 0.3603 - val_accuracy: 0.8681 - val_loss: 0.3527
Epoch 3/3
<b>250/250</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>52s</b> 209ms/step - accuracy: 0.8902 - loss: 0.3092 - val_accuracy: 0.8735 - val_loss: 0.3279
<b>313/313</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>9s</b> 29ms/step - accuracy: 0.8633 - loss: 0.3289 
LSTM with hyperparameters {&apos;NUM_EPOCHS&apos;: 3, &apos;BATCH_SIZE&apos;: 128, &apos;REVIEW_MAX_LENGTH&apos;: 500}
test loss:     0.33692342042922974
test accuracy: 0.8611999750137329
training with: {&apos;NUM_EPOCHS&apos;: 3, &apos;BATCH_SIZE&apos;: 128, &apos;REVIEW_MAX_LENGTH&apos;: 1000}
nn: LSTM - Long Short-Term Memory
<b>Model: &quot;sequential_3&quot;</b>
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃<b> Layer (type)                         </b>┃<b> Output Shape                </b>┃<b>         Param # </b>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ embedding_3 (<font color="#0087FF">Embedding</font>)              │ ?                           │     <font color="#00AF00">0</font> (unbuilt) │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ lstm_3 (<font color="#0087FF">LSTM</font>)                        │ ?                           │     <font color="#00AF00">0</font> (unbuilt) │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_3 (<font color="#0087FF">Dense</font>)                      │ ?                           │     <font color="#00AF00">0</font> (unbuilt) │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
<b> Total params: </b><font color="#00AF00">0</font> (0.00 B)
<b> Trainable params: </b><font color="#00AF00">0</font> (0.00 B)
<b> Non-trainable params: </b><font color="#00AF00">0</font> (0.00 B)
None
training the model
Epoch 1/3
<b>250/250</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>117s</b> 461ms/step - accuracy: 0.6828 - loss: 0.9914 - val_accuracy: 0.8654 - val_loss: 0.3577
Epoch 2/3
<b>250/250</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>113s</b> 452ms/step - accuracy: 0.8656 - loss: 0.3617 - val_accuracy: 0.8820 - val_loss: 0.3116
Epoch 3/3
<b>250/250</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>113s</b> 454ms/step - accuracy: 0.8922 - loss: 0.3082 - val_accuracy: 0.8735 - val_loss: 0.3273
<b>313/313</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>18s</b> 57ms/step - accuracy: 0.8729 - loss: 0.3146
LSTM with hyperparameters {&apos;NUM_EPOCHS&apos;: 3, &apos;BATCH_SIZE&apos;: 128, &apos;REVIEW_MAX_LENGTH&apos;: 1000}
test loss:     0.3225123882293701
test accuracy: 0.8700000047683716
training with: {&apos;NUM_EPOCHS&apos;: 6, &apos;BATCH_SIZE&apos;: 64, &apos;REVIEW_MAX_LENGTH&apos;: 500}
nn: LSTM - Long Short-Term Memory
<b>Model: &quot;sequential_4&quot;</b>
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃<b> Layer (type)                         </b>┃<b> Output Shape                </b>┃<b>         Param # </b>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ embedding_4 (<font color="#0087FF">Embedding</font>)              │ ?                           │     <font color="#00AF00">0</font> (unbuilt) │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ lstm_4 (<font color="#0087FF">LSTM</font>)                        │ ?                           │     <font color="#00AF00">0</font> (unbuilt) │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_4 (<font color="#0087FF">Dense</font>)                      │ ?                           │     <font color="#00AF00">0</font> (unbuilt) │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
<b> Total params: </b><font color="#00AF00">0</font> (0.00 B)
<b> Trainable params: </b><font color="#00AF00">0</font> (0.00 B)
<b> Non-trainable params: </b><font color="#00AF00">0</font> (0.00 B)
None
training the model
Epoch 1/6
<b>500/500</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>76s</b> 150ms/step - accuracy: 0.7234 - loss: 0.8202 - val_accuracy: 0.8684 - val_loss: 0.3497
Epoch 2/6
<b>500/500</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>75s</b> 149ms/step - accuracy: 0.8590 - loss: 0.3870 - val_accuracy: 0.8796 - val_loss: 0.3245
Epoch 3/6
<b>500/500</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>75s</b> 149ms/step - accuracy: 0.8963 - loss: 0.2995 - val_accuracy: 0.8770 - val_loss: 0.3164
Epoch 4/6
<b>500/500</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>75s</b> 149ms/step - accuracy: 0.9070 - loss: 0.2676 - val_accuracy: 0.8692 - val_loss: 0.3346
Epoch 5/6
<b>500/500</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>75s</b> 149ms/step - accuracy: 0.9156 - loss: 0.2455 - val_accuracy: 0.8676 - val_loss: 0.3415
<b>313/313</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>9s</b> 29ms/step - accuracy: 0.8735 - loss: 0.3190   
LSTM with hyperparameters {&apos;NUM_EPOCHS&apos;: 6, &apos;BATCH_SIZE&apos;: 64, &apos;REVIEW_MAX_LENGTH&apos;: 500}
test loss:     0.32418251037597656
test accuracy: 0.8719000220298767
training with: {&apos;NUM_EPOCHS&apos;: 6, &apos;BATCH_SIZE&apos;: 64, &apos;REVIEW_MAX_LENGTH&apos;: 1000}
nn: LSTM - Long Short-Term Memory
<b>Model: &quot;sequential_5&quot;</b>
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃<b> Layer (type)                         </b>┃<b> Output Shape                </b>┃<b>         Param # </b>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ embedding_5 (<font color="#0087FF">Embedding</font>)              │ ?                           │     <font color="#00AF00">0</font> (unbuilt) │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ lstm_5 (<font color="#0087FF">LSTM</font>)                        │ ?                           │     <font color="#00AF00">0</font> (unbuilt) │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_5 (<font color="#0087FF">Dense</font>)                      │ ?                           │     <font color="#00AF00">0</font> (unbuilt) │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
<b> Total params: </b><font color="#00AF00">0</font> (0.00 B)
<b> Trainable params: </b><font color="#00AF00">0</font> (0.00 B)
<b> Non-trainable params: </b><font color="#00AF00">0</font> (0.00 B)
None
training the model
Epoch 1/6
<b>500/500</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>164s</b> 324ms/step - accuracy: 0.7090 - loss: 0.8514 - val_accuracy: 0.8656 - val_loss: 0.3546
Epoch 2/6
<b>500/500</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>161s</b> 322ms/step - accuracy: 0.8720 - loss: 0.3481 - val_accuracy: 0.8815 - val_loss: 0.3133
Epoch 3/6
<b>500/500</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>161s</b> 323ms/step - accuracy: 0.8914 - loss: 0.2985 - val_accuracy: 0.8791 - val_loss: 0.3177
Epoch 4/6
<b>500/500</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>162s</b> 323ms/step - accuracy: 0.9023 - loss: 0.2794 - val_accuracy: 0.8785 - val_loss: 0.3337
<b>313/313</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>18s</b> 57ms/step - accuracy: 0.8778 - loss: 0.3135  
LSTM with hyperparameters {&apos;NUM_EPOCHS&apos;: 6, &apos;BATCH_SIZE&apos;: 64, &apos;REVIEW_MAX_LENGTH&apos;: 1000}
test loss:     0.3183320164680481
test accuracy: 0.8769999742507935
training with: {&apos;NUM_EPOCHS&apos;: 6, &apos;BATCH_SIZE&apos;: 128, &apos;REVIEW_MAX_LENGTH&apos;: 500}
nn: LSTM - Long Short-Term Memory
<b>Model: &quot;sequential_6&quot;</b>
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃<b> Layer (type)                         </b>┃<b> Output Shape                </b>┃<b>         Param # </b>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ embedding_6 (<font color="#0087FF">Embedding</font>)              │ ?                           │     <font color="#00AF00">0</font> (unbuilt) │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ lstm_6 (<font color="#0087FF">LSTM</font>)                        │ ?                           │     <font color="#00AF00">0</font> (unbuilt) │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_6 (<font color="#0087FF">Dense</font>)                      │ ?                           │     <font color="#00AF00">0</font> (unbuilt) │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
<b> Total params: </b><font color="#00AF00">0</font> (0.00 B)
<b> Trainable params: </b><font color="#00AF00">0</font> (0.00 B)
<b> Non-trainable params: </b><font color="#00AF00">0</font> (0.00 B)
None
training the model
Epoch 1/6
<b>250/250</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>54s</b> 208ms/step - accuracy: 0.6875 - loss: 0.9927 - val_accuracy: 0.8620 - val_loss: 0.3671
Epoch 2/6
<b>250/250</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>52s</b> 207ms/step - accuracy: 0.8651 - loss: 0.3683 - val_accuracy: 0.8730 - val_loss: 0.3320
Epoch 3/6
<b>250/250</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>52s</b> 206ms/step - accuracy: 0.8899 - loss: 0.3081 - val_accuracy: 0.8577 - val_loss: 0.3538
Epoch 4/6
<b>250/250</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>52s</b> 208ms/step - accuracy: 0.8973 - loss: 0.2918 - val_accuracy: 0.8665 - val_loss: 0.3427
<b>313/313</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>9s</b> 29ms/step - accuracy: 0.8678 - loss: 0.3335 
LSTM with hyperparameters {&apos;NUM_EPOCHS&apos;: 6, &apos;BATCH_SIZE&apos;: 128, &apos;REVIEW_MAX_LENGTH&apos;: 500}
test loss:     0.3389231562614441
test accuracy: 0.8677999973297119
training with: {&apos;NUM_EPOCHS&apos;: 6, &apos;BATCH_SIZE&apos;: 128, &apos;REVIEW_MAX_LENGTH&apos;: 1000}
nn: LSTM - Long Short-Term Memory
<b>Model: &quot;sequential_7&quot;</b>
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃<b> Layer (type)                         </b>┃<b> Output Shape                </b>┃<b>         Param # </b>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ embedding_7 (<font color="#0087FF">Embedding</font>)              │ ?                           │     <font color="#00AF00">0</font> (unbuilt) │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ lstm_7 (<font color="#0087FF">LSTM</font>)                        │ ?                           │     <font color="#00AF00">0</font> (unbuilt) │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_7 (<font color="#0087FF">Dense</font>)                      │ ?                           │     <font color="#00AF00">0</font> (unbuilt) │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
<b> Total params: </b><font color="#00AF00">0</font> (0.00 B)
<b> Trainable params: </b><font color="#00AF00">0</font> (0.00 B)
<b> Non-trainable params: </b><font color="#00AF00">0</font> (0.00 B)
None
training the model
Epoch 1/6
<b>250/250</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>116s</b> 455ms/step - accuracy: 0.6956 - loss: 1.0033 - val_accuracy: 0.8709 - val_loss: 0.3468
Epoch 2/6
<b>250/250</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>113s</b> 450ms/step - accuracy: 0.8643 - loss: 0.3628 - val_accuracy: 0.8816 - val_loss: 0.3168
Epoch 3/6
<b>250/250</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>113s</b> 450ms/step - accuracy: 0.8890 - loss: 0.3145 - val_accuracy: 0.8636 - val_loss: 0.3504
Epoch 4/6
<b>250/250</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>112s</b> 448ms/step - accuracy: 0.9046 - loss: 0.2757 - val_accuracy: 0.8708 - val_loss: 0.3293
<b>313/313</b> <font color="#26A269">━━━━━━━━━━━━━━━━━━━━</font> <b>18s</b> 56ms/step - accuracy: 0.8794 - loss: 0.3159
LSTM with hyperparameters {&apos;NUM_EPOCHS&apos;: 6, &apos;BATCH_SIZE&apos;: 128, &apos;REVIEW_MAX_LENGTH&apos;: 1000}
test loss:     0.3236008584499359
test accuracy: 0.8784999847412109

real	50m50.546s
user	353m7.489s
sys	32m45.474s
</pre>
