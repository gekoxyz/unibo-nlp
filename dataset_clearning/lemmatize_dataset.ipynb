{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/geko/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/geko/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /Users/geko/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    50000.000000\n",
      "mean       858.389040\n",
      "std        658.428061\n",
      "min         22.000000\n",
      "25%        452.000000\n",
      "50%        633.000000\n",
      "75%       1044.000000\n",
      "max       9434.000000\n",
      "Name: text, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "# read processed data\n",
    "data = pd.read_csv('./imdb_processed_full.csv')\n",
    "print(data['text'].str.len().describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "def tokenize(text):\n",
    "  return word_tokenize(text)\n",
    "\n",
    "def rm_stopwords(text):\n",
    "  return [i for i in text if i not in stopwords]\n",
    "\n",
    "def lemmatize(text):\n",
    "  lemmatizer = WordNetLemmatizer()    \n",
    "  lemmas = [lemmatizer.lemmatize(t) for t in text]\n",
    "  # make sure lemmas does not contains stopwords\n",
    "  return rm_stopwords(lemmas)\n",
    "\n",
    "def preprocess_pipeline(text):\n",
    "  tokens = tokenize(text)\n",
    "  no_stopwords = rm_stopwords(tokens)\n",
    "  lemmas = lemmatize(no_stopwords)\n",
    "  return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                                     text  label\n",
      "0      rented curious yellow video store controversy ...      0\n",
      "1      curious yellow risible pretentious steaming pi...      0\n",
      "2      avoid making type film future film interesting...      0\n",
      "3      film probably inspired godard masculin fÃ©minin...      0\n",
      "4      oh brother hearing ridiculous film umpteen yea...      0\n",
      "...                                                  ...    ...\n",
      "49995  got around seeing monster man yesterday long w...      1\n",
      "49996  got part competition prize watched really expe...      1\n",
      "49997  got monster man box set three film mainly want...      1\n",
      "49998  five minute started feel naff looking got comp...      1\n",
      "49999  caught movie sci fi channel recently actually ...      1\n",
      "\n",
      "[50000 rows x 2 columns]>\n",
      "count    50000.000000\n",
      "mean       805.422300\n",
      "std        623.917502\n",
      "min         17.000000\n",
      "25%        420.000000\n",
      "50%        592.000000\n",
      "75%        978.000000\n",
      "max       9133.000000\n",
      "Name: text, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data['text'] = data['text'].apply(preprocess_pipeline)\n",
    "print(data.head)\n",
    "# data[['text', 'label']].to_csv('./TMP.csv', index=False, header=True)\n",
    "print(data['text'].str.len().describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
