{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# utils\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from collections import Counter\n",
    "\n",
    "# text processing\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "train_path = 'imdb/plain_text/train-00000-of-00001.parquet'\n",
    "test_path = 'imdb/plain_text/test-00000-of-00001.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(train_path)\n",
    "df_test = pd.read_parquet(test_path)\n",
    "\n",
    "df = pd.concat([df_train, df_test], ignore_index=True, sort=False)\n",
    "\n",
    "# print(df.shape)\n",
    "# print(df.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_link(text):\n",
    "  return re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "\n",
    "def rm_html(text):\n",
    "  return re.sub(r'<[^>]+>', '', text)\n",
    "\n",
    "def space_bt_punct(text):\n",
    "  pattern = r'([.,!?-])'\n",
    "  s = re.sub(pattern, r' \\1 ', text)     # add whitespaces between punctuation\n",
    "  s = re.sub(r'\\s{2,}', ' ', s)        # remove double whitespaces    \n",
    "  return s\n",
    "\n",
    "def clean_html(text):\n",
    "  # Remove specific sequences\n",
    "  text = re.sub(r\"<br|/><br|/>\", \"\", text)\n",
    "  return text\n",
    "\n",
    "def rm_punct(text):\n",
    "  return re.sub(r'[\\\"\\#\\$\\%\\&\\'\\(\\)\\*\\+\\/\\:\\;\\<\\=\\>\\@\\[\\\\\\]\\^\\_\\`\\{\\|\\}\\~\\.\\!\\?\\-\\,]', ' ', text)\n",
    "\n",
    "df['text'] = df['text'].apply(rm_link)\n",
    "df['text'] = df['text'].apply(rm_html)\n",
    "df['text'] = df['text'].apply(space_bt_punct)\n",
    "df['text'] = df['text'].apply(clean_html)\n",
    "df['text'] = df['text'].apply(rm_punct)\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# VOCABULARY_SIZE = 20000\n",
    "\n",
    "# # Assuming train_data is a list of sentences\n",
    "# def build_vocab(train_data, max_size):\n",
    "#   counter = Counter(word for sentence in train_data for word in sentence.split())\n",
    "#   most_common = counter.most_common(max_size)\n",
    "#   vocab = {word: i for i, (word, _) in enumerate(most_common, start=2)}\n",
    "#   vocab['<pad>'] = 0\n",
    "#   vocab['<unk>'] = 1\n",
    "#   return vocab, most_common\n",
    "\n",
    "# # Create vocab from train_data\n",
    "# train_data = df['text'].tolist()\n",
    "# TEXT_vocab, most_common_words = build_vocab(train_data, VOCABULARY_SIZE)\n",
    "# print(f'Vocabulary size: {len(TEXT_vocab)}')\n",
    "\n",
    "# # print(\"Most common words with their frequencies:\")\n",
    "# # for word, freq in most_common_words:\n",
    "# #   print(f\"{word}: {freq}\")\n",
    "\n",
    "# # Convert the 'text' column to a list\n",
    "# text_list = df['text'].tolist()\n",
    "\n",
    "# # Open a file in write mode\n",
    "# with open('output.txt', 'w') as file:\n",
    "#   # Write each item on a new line\n",
    "#   for line in text_list:\n",
    "#     file.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['token_length'] = df.text.progress_apply(lambda x: len(x.split()))\n",
    "# # df.head()\n",
    "# # df['token_length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "def tokenize(text):\n",
    "  return word_tokenize(text)\n",
    "\n",
    "def rm_stopwords(text):\n",
    "  return [i for i in text if i not in stopwords]\n",
    "\n",
    "def lemmatize(text):\n",
    "  lemmatizer = WordNetLemmatizer()    \n",
    "  lemmas = [lemmatizer.lemmatize(t) for t in text]\n",
    "  # make sure lemmas does not contains sotpwords\n",
    "  return rm_stopwords(lemmas)\n",
    "\n",
    "def preprocess_pipeline(text):\n",
    "  tokens = tokenize(text)\n",
    "  no_stopwords = rm_stopwords(tokens)\n",
    "  lemmas = lemmatize(no_stopwords)\n",
    "  return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i rented i am curious yellow video store contr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am curious yellow risible pretentious steami...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if avoid making type film future this film int...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this film probably inspired godard masculin fé...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oh brother hearing ridiculous film umpteen yea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  i rented i am curious yellow video store contr...      0\n",
       "1  i am curious yellow risible pretentious steami...      0\n",
       "2  if avoid making type film future this film int...      0\n",
       "3  this film probably inspired godard masculin fé...      0\n",
       "4  oh brother hearing ridiculous film umpteen yea...      0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>just got around seeing monster man yesterday i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>i got part competition prize i watched really ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i got monster man box set three films i mainly...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>five minutes started feel naff looking got com...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>i caught movie sci fi channel recently it actu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "49995  just got around seeing monster man yesterday i...      1\n",
       "49996  i got part competition prize i watched really ...      1\n",
       "49997  i got monster man box set three films i mainly...      1\n",
       "49998  five minutes started feel naff looking got com...      1\n",
       "49999  i caught movie sci fi channel recently it actu...      1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['text', 'label']].to_csv('./imdb_processed.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
